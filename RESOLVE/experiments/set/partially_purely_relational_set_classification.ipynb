{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partially/Purely Relational SET Classification: RESOLVE vs Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 15:01:02.869352: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 15:01:05.796530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 15:01:05.796619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 15:01:06.195995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 15:01:07.033845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 15:01:10.694226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..'); sys.path.append('../');\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from setGame import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setgame = SetGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x100 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4]\n"
     ]
    }
   ],
   "source": [
    "num_cards=6\n",
    "_ = setgame.init_state(num_cards=num_cards, shuffle=False)\n",
    "hand = setgame.state.dealt_cards\n",
    "fig, axarr = plt.subplots(1, len(hand), figsize=(len(hand)*1,1))\n",
    "pi = np.random.choice(range(len(hand)), size=len(hand), replace=False)\n",
    "for i in range(len(hand)):\n",
    "    card = hand[i]\n",
    "    axarr[i].imshow(setgame.image_of_card(card[0], card[1]))\n",
    "    axarr[i].axis('off')\n",
    "plt.show()\n",
    "print(np.sort(np.argsort(pi)[0:3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SetEmbedder():\n",
    "    def __init__(self, ff_dim1=128, ff_dim2=64):\n",
    "        img_input = layers.Input(shape=(70, 50, 4))\n",
    "        x = layers.Conv2D(8, (5, 5), activation='tanh')(img_input)\n",
    "        x = layers.MaxPooling2D((8,8))(x)\n",
    "        x = layers.Conv2D(8, (5, 5), activation='relu')(x)\n",
    "        #x = layers.MaxPooling2D((2,2))(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(ff_dim1, activation='relu')(x)\n",
    "        x = layers.Dense(ff_dim2, activation='tanh')(x)\n",
    "        outputs = layers.Dense(12, activation='sigmoid')(x)\n",
    "        self.model = Model(inputs=img_input, outputs=outputs)\n",
    "        self.embed = Model(self.model.input, self.model.layers[2].output)   # change the self.model.layers[2] to layers[-1] to get purely relational task\n",
    "        self.model.summary()\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n",
    "        self.model_initial_weights = self.model.get_weights()\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=2):\n",
    "        self.model.set_weights(self.model_initial_weights)\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        out = self.model.predict(X_test, verbose=0)\n",
    "        return out\n",
    "\n",
    "    def embed(self, X_test):\n",
    "        out = self.embed(X_test, verbose=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(attrs):\n",
    "    color = {'red':[1,0,0], 'green':[0,1,0], 'purple':[0,0,1]}\n",
    "    pattern = {'empty':[1,0,0], 'striped':[0,1,0], 'solid':[0,0,1]}\n",
    "    shape = {'diamond':[1,0,0], 'oval':[0,1,0], 'squiggle':[0,0,1]}\n",
    "    number = {'one':[1,0,0], 'two':[0,1,0], 'three':[0,0,1]}\n",
    "    binary_attrs = number[attrs[0]] + color[attrs[1]] + pattern[attrs[2]] + shape[attrs[3]]\n",
    "    return binary_attrs\n",
    "\n",
    "n = 1000\n",
    "X = np.empty((n, 70, 50, 4), dtype=np.float32)\n",
    "y = np.empty((n, 12), dtype=int)\n",
    "\n",
    "card_coord = [(i,j) for i in np.arange(9) for j in np.arange(9)]\n",
    "for i in np.arange(n):\n",
    "    c = np.random.choice(np.arange(81), size=1)[0]\n",
    "    (row, col) = card_coord[c]\n",
    "    attrs = setgame.attributes_of_card(row, col)\n",
    "    binary_attrs = convert_to_binary(attrs)\n",
    "    X[i] = setgame.image_of_card(row, col)\n",
    "    y[i] = binary_attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 15:01:48.450822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.638220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.638527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.642211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.642474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.642649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.843822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.843915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.843972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 15:01:49.844016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46205 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 70, 50, 4)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 66, 46, 8)         808       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 8, 5, 8)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 1, 8)           1608      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9468 (36.98 KB)\n",
      "Trainable params: 9468 (36.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 15:01:51.737581: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-09-17 15:01:57.601160: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f9208535710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-17 15:01:57.601201: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-09-17 15:01:57.743191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726599718.017121    5206 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 10s 10ms/step - loss: 0.6561 - binary_accuracy: 0.6214\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6040 - binary_accuracy: 0.6801\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5163 - binary_accuracy: 0.7560\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4460 - binary_accuracy: 0.7781\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3993 - binary_accuracy: 0.8048\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3620 - binary_accuracy: 0.8280\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8501\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3036 - binary_accuracy: 0.8643\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2810 - binary_accuracy: 0.8802\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2533 - binary_accuracy: 0.8984\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2292 - binary_accuracy: 0.9164\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2096 - binary_accuracy: 0.9227\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1901 - binary_accuracy: 0.9333\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1710 - binary_accuracy: 0.9437\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1560 - binary_accuracy: 0.9539\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1434 - binary_accuracy: 0.9593\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1329 - binary_accuracy: 0.9642\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1212 - binary_accuracy: 0.9704\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1130 - binary_accuracy: 0.9697\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1024 - binary_accuracy: 0.9791\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0932 - binary_accuracy: 0.9822\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0857 - binary_accuracy: 0.9858\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0786 - binary_accuracy: 0.9891\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0714 - binary_accuracy: 0.9929\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0625 - binary_accuracy: 0.9973\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0561 - binary_accuracy: 0.9987\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0509 - binary_accuracy: 0.9994\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0458 - binary_accuracy: 0.9996\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0408 - binary_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0369 - binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0338 - binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0308 - binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0284 - binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0264 - binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0246 - binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0229 - binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0218 - binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0202 - binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0186 - binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0174 - binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0163 - binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0154 - binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0138 - binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0125 - binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0118 - binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0113 - binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0107 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "cnn = SetEmbedder(ff_dim1=64, ff_dim2=64)\n",
    "cnn.train(X_train, y_train, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "\n",
      "\n",
      "[0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
      "\n",
      "\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "\n",
      "\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "\n",
      "\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    j = np.random.choice(range(X_test.shape[0]))\n",
    "    pred = np.round(cnn.predict(X_test[j:(j+1)]))[0]\n",
    "    pred = [int(pred[b]) for b in range(len(pred))]\n",
    "    print(list(pred))\n",
    "    print(list(y_test[j:(j+1)][0]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = cnn.predict(X_test)\n",
    "pred = np.array(np.round(out), dtype=int)\n",
    "1-np.sum(pred != y_test) / (np.prod(pred.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_classification_dataset(num_seqs):\n",
    "\n",
    "    vocab_size = 81\n",
    "    setgame = SetGame()\n",
    "    dim = cnn.embed(np.expand_dims(setgame.image_of_card(0, 0), axis=0)).numpy().squeeze().shape\n",
    "    print(dim)\n",
    "    # generate random features for each object\n",
    "    card_images = np.zeros((9, 9, dim[0]*dim[1]*dim[2]))\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            card_images[i,j] = cnn.embed(np.expand_dims(setgame.image_of_card(i, j), axis=0)).numpy().squeeze().flatten()\n",
    "\n",
    "    object_seqs = np.zeros((num_seqs, 3, dim[0]*dim[1]*dim[2]))\n",
    "    card_seqs = np.zeros((num_seqs, 3, 2), dtype=int)\n",
    "    labels = np.zeros(num_seqs, dtype=int)\n",
    "\n",
    "    for s in np.arange(0, num_seqs, 2):\n",
    "        _ = setgame.init_state(num_cards=6, shuffle=False)\n",
    "        hand = setgame.state.dealt_cards\n",
    "        for i in np.arange(3):\n",
    "            card = hand[i]\n",
    "            object_seqs[s, i] = card_images[card[0], card[1]]\n",
    "            card_seqs[s, i] = [card[0], card[1]]\n",
    "        labels[s] = 1\n",
    "        for i in np.arange(3):\n",
    "            card = hand[i+3]\n",
    "            object_seqs[s+1, i] = card_images[card[0], card[1]]\n",
    "            card_seqs[s+1, i] = [card[0], card[1]]\n",
    "        labels[s+1] = 0\n",
    "\n",
    "    return card_images, card_seqs, labels, object_seqs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 8)\n"
     ]
    }
   ],
   "source": [
    "card_images, card_seqs, labels, object_seqs = create_set_classification_dataset(num_seqs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9, 320)\n",
      "(10000, 3, 2)\n",
      "(10000,)\n",
      "(10000, 3, 320)\n"
     ]
    }
   ],
   "source": [
    "print(card_images.shape)\n",
    "print(card_seqs.shape)\n",
    "print(labels.shape)\n",
    "print(object_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.1\n",
    "\n",
    "seqs_train, seqs_test, object_seqs_train, object_seqs_test, labels_train, labels_test = train_test_split(card_seqs, object_seqs, labels, test_size=0.2)\n",
    "\n",
    "seqs_train, seqs_val, object_seqs_train, object_seqs_val, labels_train, labels_val = \\\n",
    "train_test_split(seqs_train, object_seqs_train, labels_train, test_size=val_size/(1-test_size))\n",
    "\n",
    "X_train, X_val, X_test = object_seqs_train, object_seqs_val, object_seqs_test\n",
    "y_train, y_val, y_test = labels_train, labels_val, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 3, 320), (7000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, name='binary_crossentropy')\n",
    "create_opt = lambda : tf.keras.optimizers.Adam()\n",
    "\n",
    "def create_callbacks():\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_acc', restore_best_weights=True, patience=50, start_from_epoch=30)]\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayerWithLearnableH(tf.keras.layers.Layer):\n",
    "    def __init__(self, h_size):\n",
    "        super(ConvLayerWithLearnableH, self).__init__()\n",
    "        # Initialize h as a trainable variable\n",
    "        self.h_size = h_size\n",
    "    def build(self, input_shape):\n",
    "        self.h = self.add_weight(shape=(3, self.h_size), initializer='random_normal', trainable=True)\n",
    "    def call(self, x_batch):\n",
    "        S = 3\n",
    "\n",
    "        def convolve_step(i):\n",
    "            # Flip the impulse response h[n] for proper convolution\n",
    "            h_flipped = tf.reverse(self.h[i,:], axis=[0])\n",
    "\n",
    "            # Pad each signal in the batch to allow for full convolution\n",
    "            padded_x_batch = tf.pad(x_batch[:, i, :], [[0, 0], [960, 960]])\n",
    "\n",
    "            # Reshape both signals for 1D convolution\n",
    "            x_batch_reshaped = tf.reshape(padded_x_batch, [tf.shape(padded_x_batch)[0], -1, 1])  # Shape: (batch_size, signal_length, 1)\n",
    "            h_reshaped = tf.reshape(h_flipped, [-1, 1, 1])  # Reshape filter (kernel) after flipping\n",
    "\n",
    "            # Perform 1D convolution using VALID padding for each signal in the batch\n",
    "            y_batch = tf.nn.conv1d(x_batch_reshaped, h_reshaped, stride=1, padding='VALID')\n",
    "\n",
    "            # Reshape the result back to 2D (batch_size, output_length)\n",
    "            return tf.squeeze(y_batch)\n",
    "\n",
    "        # Use tf.map_fn to apply the convolution step over the sequence dimension\n",
    "        output = tf.map_fn(convolve_step, tf.range(S), dtype=tf.float32)\n",
    "\n",
    "        # Transpose the output tensor to ensure the correct shape (batch_size, S, output_length)\n",
    "        output = tf.transpose(output, perm=[1, 0, 2])\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class SmallConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SmallConvNet, self).__init__()\n",
    "        #self.conv1 = layers.Conv1D(filters=64, kernel_size=3, padding='same')\n",
    "        self.encoder = ConvLayerWithLearnableH( h_size=1024-64+1)\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        self.ln1 = layers.LayerNormalization()\n",
    "        #self.ln2 = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        #x = self.conv1(x)\n",
    "        #x = tf.nn.silu(x)\n",
    "        #x = self.ln2(x)\n",
    "        x = self.encoder(x) \n",
    "        x = self.ln1(x)\n",
    "        x = tf.nn.silu(x)    \n",
    "        x = self.dropout(x, training=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HDSymbolicAttention(layers.Layer):\n",
    "    def __init__(self, d_model, embd_size, training, symbolic, name=\"hd_symbolic_attention\", **kwargs):\n",
    "        super(HDSymbolicAttention, self).__init__(name=name, **kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.embd_size = embd_size\n",
    "        self.symbolic = symbolic\n",
    "        self.process = SmallConvNet()\n",
    "        \n",
    "    def cosine_similarity(self, a, b):\n",
    "        dot_product = tf.reduce_mean(tf.math.sign(a) * tf.math.sign(b), axis=-1) \n",
    "        return dot_product\n",
    "\n",
    "    def create_cosine_similarity_matrix(self, X,C):\n",
    "        X_i_expanded = X[:, tf.newaxis, :, :]  \n",
    "        X_j_expanded = C[:, :, tf.newaxis, :]  \n",
    "        X_i_plus_X_j = X_i_expanded + X_j_expanded  \n",
    "\n",
    "        S = self.cosine_similarity(X_i_expanded, X_i_plus_X_j)\n",
    "          \n",
    "        return tf.nn.softmax(S,axis=-1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        normal_initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "        self.Symbols = tf.Variable(normal_initializer(shape=(3, self.embd_size)), name='symbols', trainable=True)\n",
    "        super(HDSymbolicAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, values):\n",
    "        self.S3 = tf.zeros_like(values)\n",
    "        values_projected = self.process(values)\n",
    "        symbol_projected = self.process(self.S3 +self.Symbols)   \n",
    "\n",
    "        #values_projected = tf.nn.tanh(tf.einsum('bij,jk->bik',values,hd_encoder))\n",
    "        if self.symbolic:\n",
    "            scores = self.create_cosine_similarity_matrix(values_projected,symbol_projected)\n",
    "        else:\n",
    "            scores = self.create_cosine_similarity_matrix(values_projected,values_projected) \n",
    "        attention_output = tf.matmul(scores,values_projected)\n",
    "        O = tf.nn.swish(attention_output*symbol_projected)\n",
    "        return O\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESOLVE Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_modules import Encoder, Decoder, AddPositionalEmbedding\n",
    "from abstracters import SymbolicAbstracter, RelationalAbstracter\n",
    "\n",
    "class RESOLVE(tf.keras.Model):\n",
    "    def __init__(self, num_layers, num_heads, dff, embedding_dim, training, symbolic, dropout_rate=0.1):\n",
    "        super(RESOLVE, self).__init__()\n",
    "        \n",
    "        self.source_embedder = layers.TimeDistributed(layers.Dense(embedding_dim), name='source_embedder')\n",
    "        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n",
    "        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n",
    "        self.fc = layers.Dense(64, activation='relu')\n",
    "        self.mha = HDSymbolicAttention(1024, 64,training = training, symbolic = symbolic)\n",
    "        self.flattener = layers.Flatten()\n",
    "        self.dropout = layers.Dropout(0.1)\n",
    "        self.bn1 = layers.Normalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.final_layer = layers.Dense(1, name='final_layer', activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.source_embedder(inputs)\n",
    "        x = self.pos_embedding_adder_input(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.mha(x) \n",
    "        x = self.bn1(x)\n",
    "        x = self.flattener(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nvsa\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " source_embedder (TimeDistr  multiple                  20544     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " add_pos_embedding_input (A  multiple                  0         \n",
      " ddPositionalEmbedding)                                          \n",
      "                                                                 \n",
      " encoder (Encoder)           multiple                  149888    \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " hd_symbolic_attention (HDS  multiple                  5123      \n",
      " ymbolicAttention)                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " normalization (Normalizati  multiple                  2049      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " batch_normalization (Batch  multiple                  0 (unused)\n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " final_layer (Dense)         multiple                  3073      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184837 (722.02 KB)\n",
      "Trainable params: 182788 (714.02 KB)\n",
      "Non-trainable params: 2049 (8.01 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transformer_model = RESOLVE(num_layers=2, num_heads=4, dff=64, embedding_dim=64, dropout_rate=0.1, training=True, symbolic=False)\n",
    "transformer_model.compile(loss=loss, optimizer=create_opt(), metrics=['acc'])\n",
    "transformer_model(X_train[:32]); # build\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6213 - acc: 0.7885\n",
      "(900, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3898 - acc: 0.8415\n",
      "(1300, 3, 320)\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.3702 - acc: 0.8440\n",
      "(1700, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3736 - acc: 0.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:51<03:27, 51.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8241 - acc: 0.7830\n",
      "(900, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3800 - acc: 0.8435\n",
      "(1300, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3788 - acc: 0.8365\n",
      "(1700, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3674 - acc: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [01:41<02:31, 50.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5527 - acc: 0.8030\n",
      "(900, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3706 - acc: 0.8455\n",
      "(1300, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3729 - acc: 0.8435\n",
      "(1700, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3689 - acc: 0.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [02:34<01:42, 51.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 320)\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3959 - acc: 0.8445\n",
      "(900, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4245 - acc: 0.8350\n",
      "(1300, 3, 320)\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3877 - acc: 0.8385\n",
      "(1700, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3722 - acc: 0.8465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [03:30<00:53, 53.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 320)\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4032 - acc: 0.8130\n",
      "(900, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3711 - acc: 0.8455\n",
      "(1300, 3, 320)\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3728 - acc: 0.8455\n",
      "(1700, 3, 320)\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3693 - acc: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [04:19<00:00, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.833899998664856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        model = RESOLVE(num_layers=2, num_heads=4, dff=64, embedding_dim=64, dropout_rate=0.1, training=True, symbolic=False)\n",
    "        model(X_train[:32])\n",
    "        model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        print(X_train_.shape)\n",
    "        model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_modules import Encoder, Decoder, AddPositionalEmbedding\n",
    "from abstracters import RelationalAbstracter\n",
    "from abstractor import Abstractor\n",
    "\n",
    "def create_abstractor(encoder_kwargs, abstractor_kwargs, embedding_dim, dropout_rate=0.1, name='abstractor'):\n",
    "    inputs = layers.Input(shape=object_seqs_train.shape[1:], name='input_seq')\n",
    "    object_embedder = tf.keras.Sequential([layers.Dense(embedding_dim)])\n",
    "    source_embedder = layers.TimeDistributed(object_embedder, name='source_embedder')\n",
    "    pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n",
    "    #if encoder_kwargs:\n",
    "    encoder = Encoder(**encoder_kwargs, name='encoder')\n",
    "    abstractor = RelationalAbstracter(**abstractor_kwargs, name='abstractor')\n",
    "    flattener = layers.Flatten()\n",
    "    final_layer = layers.Dense(1, name='final_layer',activation='sigmoid')\n",
    "    fc = layers.Dense(64,activation='relu')\n",
    "    \n",
    "    x = source_embedder(inputs)\n",
    "    x = source_embedder(inputs)\n",
    "    x = pos_embedding_adder_input(x)\n",
    "    x = encoder(x)\n",
    "    x = fc(x)   \n",
    "    x = abstractor(x)\n",
    "    x = flattener(x)\n",
    "    logits = final_layer(x)\n",
    "\n",
    "    abstractor_model = tf.keras.Model(inputs=inputs, outputs=logits, name=name)\n",
    "    return abstractor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"abstractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_seq (InputLayer)      [(None, 3, 320)]          0         \n",
      "                                                                 \n",
      " source_embedder (TimeDistr  (None, 3, 64)             20544     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " add_pos_embedding_input (A  (None, 3, 64)             0         \n",
      " ddPositionalEmbedding)                                          \n",
      "                                                                 \n",
      " encoder (Encoder)           (None, 3, 64)             149888    \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 3, 64)             4160      \n",
      "                                                                 \n",
      " abstractor (RelationalAbst  (None, 3, 64)             150080    \n",
      " racter)                                                         \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " final_layer (Dense)         (None, 1)                 193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324865 (1.24 MB)\n",
      "Trainable params: 324865 (1.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_kwargs = dict(num_layers=2, num_heads=4, dff=64, dropout_rate=0.1)\n",
    "abstractor_kwargs = dict(num_layers=2, num_heads=4, dff=64,\n",
    "     use_pos_embedding=True, mha_activation_type='softmax', dropout_rate=0.1)\n",
    "\n",
    "abstractor_model_kwargs = dict(encoder_kwargs=encoder_kwargs, abstractor_kwargs=abstractor_kwargs, embedding_dim=64)\n",
    "abstractor_model = create_abstractor(**abstractor_model_kwargs)\n",
    "\n",
    "abstractor_model.compile(loss=loss, optimizer=create_opt(), metrics=['acc'])\n",
    "abstractor_model(X_train[:32]); # build\n",
    "abstractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 1.5056 - acc: 0.5645\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6602 - acc: 0.8090\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3859 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4591 - acc: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:39<02:36, 39.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 1.3063 - acc: 0.5430\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8620 - acc: 0.7310\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3812 - acc: 0.8385\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3939 - acc: 0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [01:20<02:01, 40.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3739 - acc: 0.5560\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2865 - acc: 0.5845\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5928 - acc: 0.8050\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3638 - acc: 0.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [01:59<01:19, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3404 - acc: 0.5705\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7076 - acc: 0.8025\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5074 - acc: 0.8120\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4230 - acc: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [02:38<00:39, 39.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 1.6636 - acc: 0.5690\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4606 - acc: 0.8185\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3959 - acc: 0.8280\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3794 - acc: 0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [03:18<00:00, 39.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.7418749988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        transformer_model = create_abstractor(**abstractor_model_kwargs)\n",
    "        transformer_model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_abstractor.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6068 - acc: 0.7620\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4110 - acc: 0.8265\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3823 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3715 - acc: 0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:22<01:30, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6376 - acc: 0.7590\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4637 - acc: 0.7915\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3752 - acc: 0.8435\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3801 - acc: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [00:49<01:14, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5974 - acc: 0.7890\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3813 - acc: 0.8460\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3812 - acc: 0.8430\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3638 - acc: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [01:12<00:48, 24.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4969 - acc: 0.7950\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3852 - acc: 0.8445\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3843 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3854 - acc: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [01:35<00:23, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4351 - acc: 0.8035\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4015 - acc: 0.8270\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3687 - acc: 0.8420\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4356 - acc: 0.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [01:59<00:00, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.8211250007152557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformer_modules import Encoder, Decoder, AddPositionalEmbedding\n",
    "from abstracters import RelationalAbstracter\n",
    "from abstractor import Abstractor\n",
    "\n",
    "def create_transformer(encoder_kwargs, embedding_dim, dropout_rate=0.1, name='abstractor'):\n",
    "    inputs = layers.Input(shape=object_seqs_train.shape[1:], name='input_seq')\n",
    "    object_embedder = tf.keras.Sequential([layers.Dense(embedding_dim)])\n",
    "    source_embedder = layers.TimeDistributed(object_embedder, name='source_embedder')\n",
    "    pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n",
    "    encoder = Encoder(**encoder_kwargs, name='encoder')\n",
    "    flattener = layers.Flatten()\n",
    "    final_layer = layers.Dense(1, name='final_layer',activation='sigmoid')\n",
    "    fc = layers.Dense(64,activation='relu')\n",
    "    \n",
    "    x = source_embedder(inputs)\n",
    "    x = source_embedder(inputs)\n",
    "    x = pos_embedding_adder_input(x)\n",
    "    x = encoder(x)\n",
    "    x = fc(x)   \n",
    "    x = flattener(x)\n",
    "    logits = final_layer(x)\n",
    "\n",
    "    abstractor_model = tf.keras.Model(inputs=inputs, outputs=logits, name=name)\n",
    "    return abstractor_model\n",
    "\n",
    "\n",
    "\n",
    "encoder_kwargs = dict(num_layers=2, num_heads=4, dff=64, dropout_rate=0.1)\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        transformer_model = create_transformer(encoder_kwargs, embedding_dim=64)\n",
    "        transformer_model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_transformer.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CorelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_head_relation import MultiHeadRelation\n",
    "\n",
    "def create_corelnet(embedding_dim, activation='softmax', name='corelnet'):\n",
    "    inputs = layers.Input(shape=object_seqs_train.shape[1:], name='input_seq')\n",
    "    object_embedder = tf.keras.Sequential([layers.Dense(embedding_dim)])\n",
    "    source_embedder = layers.TimeDistributed(object_embedder, name='source_embedder')\n",
    "    activation = layers.Softmax(axis=1) if activation == 'softmax' else layers.Activation(activation)\n",
    "    mhr = MultiHeadRelation(rel_dim=1, proj_dim=None, symmetric=True, dense_kwargs=dict(use_bias=False))\n",
    "    flattener = layers.Flatten()\n",
    "    final_layer = layers.Dense(2, name='final_layer')\n",
    "\n",
    "    x = source_embedder(inputs)\n",
    "    x = mhr(x)\n",
    "    x = activation(x)\n",
    "    x = flattener(x)\n",
    "    logits = final_layer(x)\n",
    "\n",
    "    corelnet_model = tf.keras.Model(inputs=inputs, outputs=logits, name=name)\n",
    "    return corelnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_head_relation import MultiHeadRelation\n",
    "\n",
    "def create_mlp(embedding_dim, activation='softmax', name='corelnet'):\n",
    "    inputs = layers.Input(shape=object_seqs_train.shape[1:], name='input_seq')\n",
    "    object_embedder = tf.keras.Sequential([layers.Dense(embedding_dim)])\n",
    "    source_embedder = layers.TimeDistributed(object_embedder, name='source_embedder')\n",
    "    flattener = layers.Flatten()\n",
    "    final_layer = layers.Dense(2, name='final_layer')\n",
    "\n",
    "    x = source_embedder(inputs)\n",
    "    x = flattener(x)\n",
    "    logits = final_layer(x)\n",
    "\n",
    "    corelnet_model = tf.keras.Model(inputs=inputs, outputs=logits, name=name)\n",
    "    return corelnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 594us/step - loss: 7.6553 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 558us/step - loss: 7.2586 - acc: 0.4710\n",
      "63/63 [==============================] - 0s 622us/step - loss: 8.0827 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 579us/step - loss: 7.6707 - acc: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:07<00:30,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 524us/step - loss: 8.0827 - acc: 0.4705\n",
      "63/63 [==============================] - 0s 557us/step - loss: 7.6707 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 561us/step - loss: 8.0827 - acc: 0.4860\n",
      "63/63 [==============================] - 0s 799us/step - loss: 7.6707 - acc: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [00:15<00:23,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 762us/step - loss: 7.6707 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 598us/step - loss: 8.0827 - acc: 0.4860\n",
      "63/63 [==============================] - 0s 795us/step - loss: 7.2586 - acc: 0.5020\n",
      "63/63 [==============================] - 0s 575us/step - loss: 7.6634 - acc: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [00:23<00:15,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 519us/step - loss: 7.2586 - acc: 0.4960\n",
      "63/63 [==============================] - 0s 503us/step - loss: 7.2586 - acc: 0.5235\n",
      "63/63 [==============================] - 0s 644us/step - loss: 8.0827 - acc: 0.4785\n",
      "63/63 [==============================] - 0s 543us/step - loss: 8.0827 - acc: 0.4960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [00:30<00:07,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 522us/step - loss: 5.6762 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 679us/step - loss: 7.2586 - acc: 0.4720\n",
      "63/63 [==============================] - 0s 518us/step - loss: 6.8385 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 759us/step - loss: 8.0827 - acc: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:38<00:00,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.49647499769926073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        corelnet_model_kwargs = dict(embedding_dim=64, activation='softmax')\n",
    "        corelnet_model_nosoftmax_kwargs = dict(embedding_dim=64, activation='linear')\n",
    "        transformer_model = create_mlp(**corelnet_model_nosoftmax_kwargs)\n",
    "        transformer_model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_mlp.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"corelnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_seq (InputLayer)      [(None, 3, 320)]          0         \n",
      "                                                                 \n",
      " source_embedder (TimeDistr  (None, 3, 64)             20544     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " multi_head_relation (Multi  (None, 3, 1)              4096      \n",
      " HeadRelation)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3, 1)              0         \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 3)                 0         \n",
      "                                                                 \n",
      " final_layer (Dense)         (None, 2)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24648 (96.28 KB)\n",
      "Trainable params: 24648 (96.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "corelnet_model_kwargs = dict(embedding_dim=64, activation='softmax')\n",
    "corelnet_model_nosoftmax_kwargs = dict(embedding_dim=64, activation='linear')\n",
    "corelnet_model = create_corelnet(**corelnet_model_nosoftmax_kwargs)\n",
    "corelnet_model.compile(loss=loss, optimizer=create_opt(), metrics=['acc'])\n",
    "corelnet_model(X_train[:32]); # build\n",
    "corelnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 752us/step - loss: 8.0827 - acc: 0.5295\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.2586 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 781us/step - loss: 7.6707 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 882us/step - loss: 7.4708 - acc: 0.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:09<00:37,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 674us/step - loss: 7.2586 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 910us/step - loss: 8.0827 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 947us/step - loss: 8.0492 - acc: 0.4880\n",
      "63/63 [==============================] - 0s 709us/step - loss: 7.6707 - acc: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [00:18<00:27,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 714us/step - loss: 7.4479 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6707 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.5534 - acc: 0.4800\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6707 - acc: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [00:26<00:17,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 891us/step - loss: 8.0902 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.2586 - acc: 0.5240\n",
      "63/63 [==============================] - 0s 882us/step - loss: 7.6707 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 7.6707 - acc: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [00:35<00:08,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6647 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 933us/step - loss: 8.0827 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.2586 - acc: 0.4760\n",
      "63/63 [==============================] - 0s 689us/step - loss: 7.8777 - acc: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:43<00:00,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.4939000025391579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        corelnet_model_kwargs = dict(embedding_dim=64, activation='softmax')\n",
    "        corelnet_model_nosoftmax_kwargs = dict(embedding_dim=64, activation='linear')\n",
    "        transformer_model = create_corelnet(**corelnet_model_nosoftmax_kwargs)\n",
    "        transformer_model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_correlnet.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "class PrediNet(tf.keras.layers.Layer):\n",
    "    \"\"\"PrediNet layer (Shanahan et al. 2020)\"\"\"\n",
    "\n",
    "    def __init__(self, key_dim, n_heads, n_relations, add_temp_tag=False):\n",
    "        \"\"\"create PrediNet layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key_dim : int\n",
    "            key dimension\n",
    "        n_heads : int\n",
    "            number of heads\n",
    "        n_relations : int\n",
    "            number of relations\n",
    "        add_temp_tag : bool, optional\n",
    "            whether to add temporal tag to object representations, by default False\n",
    "        \"\"\"\n",
    "\n",
    "        super(PrediNet, self).__init__()\n",
    "        self.key_dim = key_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.n_relations = n_relations\n",
    "        self.add_temp_tag = add_temp_tag\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, self.n_objs, obj_dim = input_shape\n",
    "\n",
    "        self.obj_dim = obj_dim\n",
    "        self.obj_tagged_dim = self.obj_dim + 1\n",
    "\n",
    "        self.W_k = layers.Dense(self.key_dim, use_bias=False)\n",
    "        self.W_q1 = layers.Dense(self.n_heads * self.key_dim, use_bias=False)\n",
    "        self.W_q2 = layers.Dense(self.n_heads * self.key_dim, use_bias=False)\n",
    "        self.W_s = layers.Dense(self.n_relations, use_bias=False)\n",
    "\n",
    "        self.relu = layers.ReLU()\n",
    "        self.softmax = layers.Softmax(axis=1)\n",
    "        self.flatten = layers.Flatten()\n",
    "\n",
    "        # create temporal tag\n",
    "        if self.add_temp_tag:\n",
    "            self.temp_tag = tf.convert_to_tensor(np.arange(self.n_objs), dtype=tf.float32)\n",
    "            self.temp_tag = tf.expand_dims(self.temp_tag, axis=0)\n",
    "            self.temp_tag = tf.expand_dims(self.temp_tag, axis=2)\n",
    "\n",
    "\n",
    "    def call(self, obj_seq):\n",
    "\n",
    "        # append temporal tag to all z\n",
    "        if self.add_temp_tag:\n",
    "            temp_tag = tf.tile(self.temp_tag, multiples=[tf.shape(obj_seq)[0], 1, 1])\n",
    "            obj_seq = tf.concat([obj_seq, temp_tag], axis=2)\n",
    "\n",
    "        # Get keys for all objects in sequence\n",
    "        K = self.W_k(obj_seq)\n",
    "\n",
    "        # get queries for objects 1 and 2\n",
    "        obj_seq_flat = self.flatten(obj_seq)\n",
    "        Q1 = self.W_q1(obj_seq_flat)\n",
    "        Q2 = self.W_q2(obj_seq_flat)\n",
    "\n",
    "        # reshape queries to separate heads\n",
    "        Q1_reshaped = tf.reshape(Q1, shape=(-1, self.n_heads, self.key_dim))\n",
    "        Q2_reshaped = tf.reshape(Q2, shape=(-1, self.n_heads, self.key_dim))\n",
    "\n",
    "        # extract attended objects\n",
    "        E1 = (self.softmax(tf.reduce_sum(Q1_reshaped[:, tf.newaxis, :, :] * K[:, :, tf.newaxis, :], axis=3))\n",
    "             [:, :, :, tf.newaxis] * obj_seq[:, :, tf.newaxis, :])\n",
    "        E1 = tf.reduce_sum(E1, axis=1)\n",
    "        E2 = (self.softmax(tf.reduce_sum(Q2_reshaped[:, tf.newaxis, :, :] * K[:, :, tf.newaxis, :], axis=3))\n",
    "              [:, :, :, tf.newaxis] * obj_seq[:, :, tf.newaxis, :])\n",
    "        E2 = tf.reduce_sum(E2, axis=1)\n",
    "\n",
    "        # compute relation vector\n",
    "        D = self.W_s(E1) - self.W_s(E2)\n",
    "\n",
    "        # add temporal position tag\n",
    "        if self.add_temp_tag:\n",
    "            D = tf.concat([D, E1[:, :, -1][:, :, tf.newaxis], E2[:, :, -1][:, :, tf.newaxis]], axis=2)\n",
    "\n",
    "        R = self.flatten(D) # concatenate heads\n",
    "\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predinet(encoder_kwargs, embedding_dim, dropout_rate=0.1, name='predinet'):\n",
    "    inputs = layers.Input(shape=object_seqs_train.shape[1:], name='input_seq')\n",
    "    object_embedder = tf.keras.Sequential([layers.Dense(embedding_dim)])\n",
    "    source_embedder = layers.TimeDistributed(object_embedder, name='source_embedder')\n",
    "    pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n",
    "    #if encoder_kwargs:\n",
    "    encoder = Encoder(**encoder_kwargs, name='encoder')\n",
    "    predinet = PrediNet(key_dim=64, n_heads=1 ,n_relations= 1, add_temp_tag=False)\n",
    "    flattener = layers.Flatten()\n",
    "    # hidden_dense = layers.Dense(64, activation='relu', name='hidden_dense')\n",
    "    final_layer = layers.Dense(1, name='final_layer',activation='sigmoid')\n",
    "    fc = layers.Dense(64,activation='relu')\n",
    "    \n",
    "    x = source_embedder(inputs)\n",
    "    x = source_embedder(inputs)\n",
    "    x = pos_embedding_adder_input(x)\n",
    "    x = encoder(x)\n",
    "    x = predinet(x)\n",
    "    x = fc(x)   \n",
    "    x = flattener(x)\n",
    "    logits = final_layer(x)\n",
    "\n",
    "    abstractor_model = tf.keras.Model(inputs=inputs, outputs=logits, name=name)\n",
    "    return abstractor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6269 - acc: 0.7175\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4508 - acc: 0.7805\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3784 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3949 - acc: 0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:28<01:53, 28.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4360 - acc: 0.8415\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3842 - acc: 0.8445\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3696 - acc: 0.8405\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3718 - acc: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [00:57<01:25, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5917 - acc: 0.7480\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3999 - acc: 0.8415\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3685 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3937 - acc: 0.8390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [01:24<00:56, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4114 - acc: 0.8420\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3648 - acc: 0.8455\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3743 - acc: 0.8410\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4487 - acc: 0.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [01:53<00:28, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5315 - acc: 0.7230\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3899 - acc: 0.8185\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3788 - acc: 0.8450\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7001 - acc: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [02:20<00:00, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.8013499975204468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        encoder_kwargs = dict(num_layers=2, num_heads=4, dff=64, dropout_rate=0.1)\n",
    "        transformer_model = create_predinet(encoder_kwargs, embedding_dim=64)\n",
    "        transformer_model.compile(loss='binary_crossentropy', optimizer=create_opt(), metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_predinet.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 320)]             0         []                            \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)       [(None, 1, 320),             0         ['input_2[0][0]']             \n",
      "                              (None, 1, 320),                                                     \n",
      "                              (None, 1, 320)]                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOp  (None, 320)                  0         ['tf.split[0][0]']            \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TF  (None, 320)                  0         ['tf.split[0][1]']            \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_2 (TF  (None, 320)                  0         ['tf.split[0][2]']            \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " sequential_219 (Sequential  (None, 32)                   51424     ['tf.compat.v1.squeeze[0][0]',\n",
      " )                                                                   'tf.compat.v1.squeeze_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.compat.v1.squeeze_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 96)                   0         ['sequential_219[0][0]',      \n",
      "                                                                     'sequential_219[1][0]',      \n",
      "                                                                     'sequential_219[2][0]']      \n",
      "                                                                                                  \n",
      " dense_542 (Dense)           (None, 64)                   6208      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_543 (Dense)           (None, 32)                   2080      ['dense_542[0][0]']           \n",
      "                                                                                                  \n",
      " dense_544 (Dense)           (None, 1)                    33        ['dense_543[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 59745 (233.38 KB)\n",
      "Trainable params: 59745 (233.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the MLP used to process the input feature vectors\n",
    "def build_mlp(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    return model\n",
    "\n",
    "# Define the adapted Logic Embedding Network for binary output\n",
    "def build_len_binary(input_shape):\n",
    "    # MLP model to process each of the input feature vectors (shape: (320,))\n",
    "    mlp_model = build_mlp((320,))\n",
    "    \n",
    "    # Input for the single feature vector (shape: (3, 320))\n",
    "    input_tensor = layers.Input(shape=(3, 320))\n",
    "    \n",
    "    # Split the input tensor into 3 separate tensors of shape (320,)\n",
    "    input1, input2, input3 = tf.split(input_tensor, num_or_size_splits=3, axis=1)\n",
    "    \n",
    "    # Squeeze the tensors to remove extra dimensions (from (1, 320) to (320,))\n",
    "    input1 = tf.squeeze(input1, axis=1)\n",
    "    input2 = tf.squeeze(input2, axis=1)\n",
    "    input3 = tf.squeeze(input3, axis=1)\n",
    "\n",
    "    # Compute embeddings for each of the input vectors\n",
    "    embedding1 = mlp_model(input1)\n",
    "    embedding2 = mlp_model(input2)\n",
    "    embedding3 = mlp_model(input3)\n",
    "    \n",
    "    # Concatenate embeddings and pass them through another dense layer\n",
    "    concatenated = layers.Concatenate()([embedding1, embedding2, embedding3])\n",
    "    reasoning_output = layers.Dense(64, activation='relu')(concatenated)\n",
    "    reasoning_output = layers.Dense(32, activation='relu')(reasoning_output)\n",
    "    \n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    output = layers.Dense(1, activation='sigmoid')(reasoning_output)\n",
    "    \n",
    "    # Build the model\n",
    "    model = models.Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Example input shape and number of feature vectors\n",
    "input_shape = (3, 320)  # 3 feature vectors of size 320 each\n",
    "len_binary_model = build_len_binary(input_shape)\n",
    "# Build the LEN model for binary output\n",
    "\n",
    "len_binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 949us/step - loss: 0.7776 - acc: 0.7485\n",
      "63/63 [==============================] - 0s 961us/step - loss: 0.5718 - acc: 0.7545\n",
      "63/63 [==============================] - 0s 956us/step - loss: 0.4280 - acc: 0.8275\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3813 - acc: 0.8345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████                                    | 1/5 [00:11<00:45, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6777 - acc: 0.7665\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4838 - acc: 0.7950\n",
      "63/63 [==============================] - 0s 841us/step - loss: 0.3922 - acc: 0.8260\n",
      "63/63 [==============================] - 0s 834us/step - loss: 0.3853 - acc: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████                           | 2/5 [00:22<00:34, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 723us/step - loss: 0.7583 - acc: 0.7325\n",
      "63/63 [==============================] - 0s 758us/step - loss: 0.4093 - acc: 0.8335\n",
      "63/63 [==============================] - 0s 740us/step - loss: 0.3929 - acc: 0.8380\n",
      "63/63 [==============================] - 0s 798us/step - loss: 0.5282 - acc: 0.7555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████                  | 3/5 [00:33<00:22, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5196 - acc: 0.7900\n",
      "63/63 [==============================] - 0s 845us/step - loss: 0.4647 - acc: 0.8135\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5512 - acc: 0.8225\n",
      "63/63 [==============================] - 0s 731us/step - loss: 0.4319 - acc: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████         | 4/5 [00:45<00:11, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8015 - acc: 0.7525\n",
      "63/63 [==============================] - 0s 974us/step - loss: 0.5975 - acc: 0.7570\n",
      "63/63 [==============================] - 0s 766us/step - loss: 0.3842 - acc: 0.8380\n",
      "63/63 [==============================] - 0s 857us/step - loss: 0.3893 - acc: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:57<00:00, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy over all seeds: 0.7987250030040741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "accuracies = []\n",
    "seeds = [2020, 2021, 2022, 2023, 2024]\n",
    "for seed in tqdm(seeds):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    seed_accuracies = []\n",
    "    for train_size in range(500, 2000, 400):\n",
    "        X_train_ = X_train_shuffled[:train_size]\n",
    "        y_train_ = y_train_shuffled[:train_size]\n",
    "        transformer_model = build_len_binary(input_shape)\n",
    "        transformer_model.compile(optimizer=create_opt(), loss='binary_crossentropy', metrics=['acc'])\n",
    "        transformer_model.fit(X_train_, y_train_, validation_data=(X_val, y_val), epochs=100, verbose=0, batch_size=512, callbacks=create_callbacks())\n",
    "        results = transformer_model.evaluate(X_test, y_test, return_dict=True)\n",
    "        seed_accuracies.append(results['acc'])\n",
    "    accuracies.append(seed_accuracies)\n",
    "accuracies_np = np.array(accuracies)\n",
    "np.save('./low_preprocessing/accuracies_LEN.npy', accuracies_np)\n",
    "mean_accuracy = np.mean(accuracies_np)\n",
    "print(f\"Mean accuracy over all seeds: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cfd9851f5ad10fee1056595cab4382bd1be8335c56803e8ccc2b0eacb646d0c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
